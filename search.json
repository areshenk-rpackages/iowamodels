[{"path":"areshenk-rpackages.github.io/iowamodels/articles/customizing_models.html","id":"internal-package-structure","dir":"Articles","previous_headings":"","what":"Internal package structure","title":"Adding new models","text":"general structure package follows: External packages (iowa) interface iowamodels wrapper functions simulateIGT() fitIGT(), provide high-level interface cmdstan models implemented iowamodels. Models implemented src/stan/<modelfile>>.stan. actual component functions (e.g. specific utility function) passed internally data stan model, imported separate .stan file. separate files stored src/stan/include, names e.g. utilityFunctions.stanfunctions. example, src/stan/fitIGT.stan – responsible model fitting – specifies general model follows: trial t, utility outcome evaluated function utility imported src/stan/include/utilityWrapper.stanfunctions, defined Note function just general wrapper calls one several utility functions depending integer argument ind. turn, utility functions defined inst/stan/include/utilityFunctions.stan. example, EU PU utility defined : Note important point: utility functions exactly signature; real win, real loss, array[] real par. package turn contains modelDetails object contained R/sysdata.rda. structure nested list containing information model component; required parameters, necessary (default) bounds. structure list follows: , fields utility, updating, temperature; named list fields corresponding included function. field index indicates corresponding value ind stan wrapper function (e.g. utility(..., ind = 1) chooses EV utility), index within parameter field specifies position parameter par argument. parameter fields also contain entries giving parameter bounds (outside package throw error), well default bounds used model fitting user specify . general structure package program illustrated , using utility function example:","code":"// Likelihood for (t in 1:NUM_TRIALS){      // Compute temperature     theta = temperature(t, temperature_params, TEMPERATURE_FUNCTION);      // Draw card     choice[t] ~ categorical_logit(theta * V);      // Compute utility     U = utility(win[t], loss[t], utility_params, UTILITY_FUNCTION);      // Update deck values     V = updating(V, U, choice[t], updating_params, UPDATING_FUNCTION); } utility(win[t], loss[t], utility_params, UTILITY_FUNCTION); real utility(real win, real loss, array[] real par, int ind){      if (ind == 1){         return utility_EU(win, loss, par);     } else if (ind == 2){         return utility_PU(win, loss, par);     } else if (ind == 3){         return utility_PU2(win, loss, par);     } else {         return 0;     } } // EU utility function (used in EV model) real utility_EU(real win, real loss, array[] real par) {     return (1-par[1]) * win - par[1] * loss; }  // Prospect utility function real utility_PU(real win, real loss, array[] real par) {     real net = win - loss;     if (net >= 0){         return pow(net, par[1]);     } else {         return -par[2] * pow(abs(net), par[1]);     } } modelDetails .  utility . .  EU . . .  index = 1 . . .  pars . . . .  w . . . . .  bounds = c(0,1) . . . . .  default_bounds = c(0, 1) . . . . .  description = \"Win/loss weighting\" . . . . .  index = 1 . .  PU . . .  index = 2 . . .  pars . . . .  A . . . . .  bounds = c(0, Inf) . . . . .  default_bounds = c(0, 1) . . . . .  description = \"Concavity of utility function\" . . . . .  index = 1 . . . .  L . . . . .  bounds = c(0, Inf) . . . . .  default_bounds = c(0, 5) . . . . .  description = \"Loss aversion\" . . . . .  index = 2"},{"path":"areshenk-rpackages.github.io/iowamodels/articles/customizing_models.html","id":"implementing-a-new-model-component","dir":"Articles","previous_headings":"","what":"Implementing a new model component","title":"Adding new models","text":"Adding new utility function iowamodels now involves following steps: Add function src/stan/include/utilityFunctions.stanfunctions, making sure matches required signature. Add new statement src/stan/include/utilityWrapper.stanfunctions, corresponding next highest value ind. Add new field modelDetails utility field – named unique keyword new utility function – populate necessary fields (.e. one subfield parameter, required fields bounds default_bounds). index field must correspond value ind calls new utility function step (2). Resave modelDetails R/sysdata.rda using save(modelDetails, file = 'R/sysdata.rda'). package recompiled, new utility function ready use. steps adding new updating temperature functions essentially identical, mutatis mutandis.","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/articles/model_structure.html","id":"specifying-a-model","dir":"Articles","previous_headings":"","what":"Specifying a model","title":"Model structure","text":"Models implemented iowamodels require specifying utility, updating, temperature functions. package implements several common versions , based models commonly reported literature. function identified keyword, utility/updating/temperature functions can mixed matched. Detailed information available options given respective articles.","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/articles/temperature_functions.html","id":"time-independent-parameters","dir":"Articles","previous_headings":"","what":"Time independent parameters","title":"Temperature functions","text":"Keyword: TIC Parameters: c (Temperature) Bounds: c∈[0,∞)c \\[0,\\infty) θ=3c \\theta = 3^c","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/articles/temperature_functions.html","id":"time-dependent-parameters","dir":"Articles","previous_headings":"","what":"Time dependent parameters","title":"Temperature functions","text":"Keyword: TDC Parameters: c (Temperature) Bounds: c∈[0,∞)c \\[0,\\infty) Description: Temperature increases increasing trials. Intended simulate gradual shift exploratory exploitative behavior. θ(t)=(t10)c \\theta(t) = \\left ( \\frac{t}{10} \\right )^c","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/articles/updating_functions.html","id":"decay-reinforcement-learning-rule","dir":"Articles","previous_headings":"","what":"Decay reinforcement learning rule","title":"Updating functions","text":"Keyword: DRL Parameters: d (Decay parameter) Bounds: d∈[0,1]d \\[0,1] Description: Valuation decks decays factor d, chosen deck c updated observed utility u. vc(u)=dvc+δcu v_c(u) = dv_c + \\delta_cu","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/articles/updating_functions.html","id":"delta-learning-rule","dir":"Articles","previous_headings":"","what":"Delta learning rule","title":"Updating functions","text":"Keyword: DEL Parameters: r (Learning rate) Bounds: r∈[0,1]r \\[0,1] Description: Updates chosen deck using reward prediction error (difference observed expected utility chosen deck) vc(u)=vc+δcr(u−vc) v_c(u) = v_c + \\delta_c r (u - v_c)","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/articles/updating_functions.html","id":"mixed-learning-rule","dir":"Articles","previous_headings":"","what":"Mixed learning rule","title":"Updating functions","text":"Keyword: ML Parameters: d (Decay parameter), r (Learning rate) Bounds: d∈[0,1]d \\[0,1], r∈[0,1]r \\[0,1] Description: Valuation decks decays trial, DRL. chosen deck updated DEL. vc(u)=(1−d)vc+δcr[u−(1−d)vc] v_c(u) = (1-d)v_c + \\delta_c r [u - (1-d)v_c]","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/articles/utility_functions.html","id":"expectance-valence-utility","dir":"Articles","previous_headings":"","what":"Expectance valence utility","title":"Utility functions","text":"Keyword: EU Parameters: w (Win/loss weighting) Bounds: w∈[0,1]w \\[0,1] Depends: Gain loss u(g,l)=(1−w)g+wl u(g,l) = (1-w)g + wl","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/articles/utility_functions.html","id":"prospect-utility","dir":"Articles","previous_headings":"","what":"Prospect utility","title":"Utility functions","text":"Keyword: PU Parameters: (Concavity), L (Loss aversion) Bounds: ∈[0,1]\\[0,1], L∈[0,∞)L \\[0, \\infty) Depends: Net outcome u(x)={xAx≥0−L|x|Ax<0 u(x) = \\begin{cases}       x^& x \\geq 0\\\\      -L|x|^& x < 0 \\end{cases}","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/articles/utility_functions.html","id":"alternative-prospect-utility","dir":"Articles","previous_headings":"","what":"Alternative prospect utility","title":"Utility functions","text":"Keyword: PU2 Parameters: (Concavity), L (Loss aversion) Bounds: ∈[0,1]\\[0,1], L∈[0,∞)L \\[0, \\infty) Depends: Gain loss u(g,l)=gA−LlA u(g,l) = g^- Ll^","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":". Maintainer.","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Areshenkoff CN (2024). iowamodels: Modular reinforcement learning models R. R package version 0.0.1, https://areshenk-rpackages.github.io/iowamodels/.","code":"@Manual{,   title = {iowamodels: Modular reinforcement learning models in R},   author = {Corson N. Areshenkoff},   year = {2024},   note = {R package version 0.0.1},   url = {https://areshenk-rpackages.github.io/iowamodels/}, }"},{"path":"areshenk-rpackages.github.io/iowamodels/index.html","id":"iowamodels-","dir":"","previous_headings":"","what":"Modular reinforcement learning models of the IGT","title":"Modular reinforcement learning models of the IGT","text":"iowamodels package backend iowa package, implements modular reinforcement learning models Iowa gambling task. Model components implemented Stan, compiled cmdstan models made available internally packages. package implements simulation fitting models constructed mixing matching various utility, updating, temperature functions; designed relatively extensible allowing users implement custom model components. addition simulating performance custom models, iowamodels also allows model fitting either maximum likelihood / maximum posteriori estimation, full posterior sampling. Currently, single subject fitting supported, support full hierarchical Bayesian fitting strong priority.","code":""},{"path":"areshenk-rpackages.github.io/iowamodels/reference/iowamodels-package.html","id":null,"dir":"Reference","previous_headings":"","what":"iowamodels: Modular reinforcement learning models for the Iowa gambling task — iowamodels-package","title":"iowamodels: Modular reinforcement learning models for the Iowa gambling task — iowamodels-package","text":"cmdstanr backend iowa package","code":""},{"path":[]}]
